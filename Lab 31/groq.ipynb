{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-ce0b17b8-dd68-4e34-83e9-d4b8f92baa34', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Fast language models are artificial intelligence (AI) models that can process and generate human-like text at incredibly high speeds, often in real-time. The importance of fast language models lies in their ability to:\\n\\n1. **Scale up language understanding**: Fast language models can process vast amounts of text data, enabling them to learn and improve rapidly. This is particularly important for applications like language translation, text classification, and sentiment analysis.\\n2. **Improve conversational AI**: Fast language models are essential for creating conversational AI systems that can engage in natural-sounding conversations. They enable AI systems to respond quickly, keeping the conversation flowing and making interactions more human-like.\\n3. **Enhance chatbots and virtual assistants**: Fast language models power chatbots and virtual assistants, allowing them to quickly understand and respond to user input. This improves customer service and user experience.\\n4. **Accelerate natural language processing**: Fast language models can perform complex natural language processing (NLP) tasks, such as named entity recognition, entity disambiguation, and language modeling, rapidly and efficiently.\\n5. **Streamline content generation**: Fast language models can generate high-quality content, such as articles, blog posts, and social media updates, quickly and at scale. This is useful for content marketing, news organizations, and social media platforms.\\n6. **Enable predictive maintenance**: Fast language models can analyze vast amounts of text data to predict equipment failures, detect anomalies, and identify potential issues before they occur.\\n7. **Support search and recommendation**: Fast language models can quickly process search queries and provide relevant recommendations, improving search engine results and personalized experiences.\\n8. **Improve accessibility**: Fast language models can be used to generate real-time subtitles, closed captions, and audio descriptions, enhancing accessibility for people with disabilities.\\n9. **Facilitate language learning**: Fast language models can provide instant feedback and corrections, helping language learners improve their skills quickly and efficiently.\\n10. **Enable real-time analytics**: Fast language models can process and analyze large amounts of text data in real-time, providing valuable insights and analytics for businesses and organizations.\\n\\nThe importance of fast language models will only continue to grow as AI becomes more pervasive and integrated into various industries and aspects of life.', role='assistant', function_call=None, tool_calls=None))], created=1732009433, model='llama3-8b-8192', object='chat.completion', system_fingerprint='fp_6a6771ae9c', usage=CompletionUsage(completion_tokens=450, prompt_tokens=18, total_tokens=468, completion_time=0.375, prompt_time=0.003243565, queue_time=0.010342093, total_time=0.378243565), x_groq={'id': 'req_01jd1wx69gezdrzn9vs70pn6m7'})\n"
     ]
    }
   ],
   "source": [
    "client = Groq(\n",
    "    api_key=\"\", # Replace with your Groq API key\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
